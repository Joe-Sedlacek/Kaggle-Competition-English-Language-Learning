{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.patches import ConnectionPatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from csv files\n",
    "all_training_data = pd.read_csv('./data/train.csv', index_col=0)\n",
    "all_vocab_words = pd.read_csv('./data/unigram_freq.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_essays = []\n",
    "all_scores = []\n",
    "\n",
    "for ind, data in enumerate(all_training_data.iterrows()):\n",
    "    text, cohes, syntax, vocab, phrase, gram, convs = data[1]\n",
    "    all_essays.append(text)\n",
    "    all_scores.append(vocab) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_all_essays = np.array(all_essays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building dictionary with vocab word as key and count as value\n",
    "vocab_dict = {}\n",
    "\n",
    "for data in all_vocab_words.iterrows():\n",
    "  vocab_dict[data[0]] = data[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_essays = []\n",
    "misspelled_perc = []\n",
    "\n",
    "for index, essay in enumerate(np_all_essays):\n",
    "  essay_wo_punc = re.sub(r'[^\\w\\s]', '', essay)\n",
    "  essay_lower = essay_wo_punc.lower()\n",
    "  split_essay = re.split('[^a-zA-Z]+', essay_lower)\n",
    "  cleaned_essays.append(split_essay)\n",
    "\n",
    "  misspell_count = 0\n",
    "  for word in split_essay:\n",
    "    if word not in vocab_dict and word != '':\n",
    "      misspell_count += 1\n",
    "  misspelled_perc.append(misspell_count / len(split_essay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_essays_per_score = {}\n",
    "sum_perc_per_score = {}\n",
    "\n",
    "for index in range(len(all_scores)):\n",
    "  if all_scores[index] not in num_essays_per_score:\n",
    "    num_essays_per_score[all_scores[index]] = 0\n",
    "    sum_perc_per_score[all_scores[index]] = 0\n",
    "  \n",
    "  num_essays_per_score[all_scores[index]] += 1\n",
    "  sum_perc_per_score[all_scores[index]] += misspelled_perc[index]\n",
    "  if all_scores[index] == 1.5:\n",
    "    print(sum_perc_per_score[1.5])\n",
    "\n",
    "scores = []\n",
    "avg_perc_per_score = []\n",
    "\n",
    "for sc in sum_perc_per_score:\n",
    "  scores.append(sc)\n",
    "  avg = sum_perc_per_score[sc] / num_essays_per_score[sc]\n",
    "  avg_perc_per_score.append(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting misspelled words vs vocab scores\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(6, 6))\n",
    "ax.scatter(all_scores, misspelled_perc, color=['blue'])\n",
    "ax.scatter(scores, avg_perc_per_score, color=['orange'], marker='D')\n",
    "ax.set_xlabel('True vocab score')\n",
    "ax.set_ylabel('Percentage of misspelled words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = len(all_vocab_words)\n",
    "top1 = num_words*0.01\n",
    "top10 = num_words*0.1\n",
    "top50 = num_words*0.5\n",
    "\n",
    "top1_words = set()\n",
    "top10_words = set()\n",
    "top50_words = set()\n",
    "\n",
    "index = 0\n",
    "for data in all_vocab_words.iterrows():\n",
    "    if index < top1:\n",
    "        top1_words.add(data[0])\n",
    "    elif index < top10:\n",
    "        top10_words.add(data[0])\n",
    "    elif index < top50:\n",
    "        top50_words.add(data[0])\n",
    "    else:\n",
    "        break\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1_count = 0\n",
    "top10_count = 0\n",
    "top50_count = 0\n",
    "other = 0\n",
    "\n",
    "for essay in cleaned_essays:\n",
    "  for word in essay:\n",
    "    if word in top1_words:\n",
    "      top1_count += 1\n",
    "    elif word in top10_words:\n",
    "      top10_count += 1\n",
    "    elif word in top50_words:\n",
    "      top50_count += 1\n",
    "    else:\n",
    "      other += 1\n",
    "\n",
    "total = top1_count + top10_count + top50_count + other\n",
    "bottom = top10_count + top50_count + other\n",
    "\n",
    "# basic pie chart parametrs\n",
    "pie1_labels = ['Top 1%', 'Top 10%', 'Top 50%', '']\n",
    "pie1_percs = [top1_count/total, top10_count/total, top50_count/total, other/total]\n",
    "\n",
    "# advanced pie chart parameters\n",
    "pie2_labels = ['Other', 'Top 1%']\n",
    "pie2_percs = [1 - (top1_count/total), top1_count/total]\n",
    "\n",
    "# bar chart parameters\n",
    "other_percs = [top10_count/bottom, top50_count/bottom, other/bottom]\n",
    "other_labels = ['Top 10%', 'Top 50%', '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, ax2 = plt.subplots()\n",
    "ax2.pie(pie1_percs, labels=pie1_labels, autopct='%1.1f%%', startangle=90)\n",
    "ax2.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on code found at https://matplotlib.org/stable/gallery/pie_and_polar_charts/bar_of_pie.html\n",
    "\n",
    "# make figure and assign axis objects\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(9, 5))\n",
    "fig.subplots_adjust(wspace=0)\n",
    "\n",
    "# pie chart parameters\n",
    "explode = [0.1, 0]\n",
    "\n",
    "# rotate so that first wedge is split by the x-axis\n",
    "angle = -180 * pie2_percs[0]\n",
    "wedges, *_ = ax1.pie(pie2_percs, autopct='%1.1f%%', startangle=angle,\n",
    "                     labels=pie2_labels, explode=explode)\n",
    "\n",
    "# bar chart parameters\n",
    "bottom = 1\n",
    "width = .2\n",
    "\n",
    "# Adding from the top matches the legend.\n",
    "for j, (height, label) in enumerate(reversed([*zip(other_percs, other_labels)])):\n",
    "    bottom -= height\n",
    "    bc = ax2.bar(0, height, width, bottom=bottom, color='C0', label=label,\n",
    "                 alpha=0.1 + 0.25 * j)\n",
    "    ax2.bar_label(bc, labels=[f\"{height:.0%}\"], label_type='center')\n",
    "\n",
    "ax2.set_title('Remaining breakdown')\n",
    "ax2.legend()\n",
    "ax2.axis('off')\n",
    "ax2.set_xlim(- 2.5 * width, 2.5 * width)\n",
    "\n",
    "# use ConnectionPatch to draw lines between the two plots\n",
    "theta1, theta2 = wedges[0].theta1, wedges[0].theta2\n",
    "center, r = wedges[0].center, wedges[0].r\n",
    "bar_height = sum(other_percs)\n",
    "\n",
    "# draw top connecting line\n",
    "x = r * np.cos(np.pi / 180 * theta2) + center[0]\n",
    "y = r * np.sin(np.pi / 180 * theta2) + center[1]\n",
    "con = ConnectionPatch(xyA=(-width / 2, bar_height), coordsA=ax2.transData,\n",
    "                      xyB=(x, y), coordsB=ax1.transData)\n",
    "con.set_color([0, 0, 0])\n",
    "con.set_linewidth(2)\n",
    "ax2.add_artist(con)\n",
    "\n",
    "# draw bottom connecting line\n",
    "x = r * np.cos(np.pi / 180 * theta1) + center[0]\n",
    "y = r * np.sin(np.pi / 180 * theta1) + center[1]\n",
    "con = ConnectionPatch(xyA=(-width / 2, 0), coordsA=ax2.transData,\n",
    "                      xyB=(x, y), coordsB=ax1.transData)\n",
    "con.set_color([0, 0, 0])\n",
    "ax2.add_artist(con)\n",
    "con.set_linewidth(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

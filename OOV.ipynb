{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import spacy\n",
    "from spacy.vocab import Vocab\n",
    "import numpy\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Embedding\n",
    "from keras.models import load_model\n",
    "import unicodecsv\n",
    "from spacy.attrs import LOWER, POS, ENT_TYPE, IS_ALPHA\n",
    "from spacy.tokens import Doc\n",
    "from spacy.matcher import Matcher\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading processed data\n",
    "data = open(r'C:\\Users\\jsedl\\Downloads\\blogtext.csv', encoding='utf-8').read()[:10000]\n",
    "#data=unicodecsv.reader(data, encoding='utf-8', delimeter = ';')\n",
    "#data = \"I think that students would benefit from learning at home,because they wont have to change and get up early in the morning to shower and do there hair. taking only classes helps them because at there house they'll be pay more attention. they will be comfortable at home. The hardest part of school is getting ready. you wake up go brush your teeth and go to your closet and look at your cloths. after you think you picked a outfit u go look in the mirror and youll either not like it or you look and see a stain. Then you'll have to change. with the online classes you can wear anything and stay home and you wont need to stress about what to wear. most students usually take showers before school. they either take it before they sleep or when they wake up. some students do both to smell good. that causes them do miss the bus and effects on there lesson time cause they come late to school. when u have online classes u wont need to miss lessons cause you can get everything set up and go take a shower and when u get out your ready to go. when your home your comfortable and you pay attention. it gives then an advantage to be smarter and even pass there classmates on class work. public schools are difficult even if you try. some teacher dont know how to teach it in then way that students understand it. that causes students to fail and they may repeat the class. \"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt to read with pandas...may need if cannot fix w other\n",
    "# myFile=open(r'C:\\Users\\jsedl\\Downloads\\blogtext.csv')\n",
    "# data=pd.read_csv(myFile, encoding = 'utf-8', quotechar='\"' ,delimiter = ';', nrows=1000000)\n",
    "# type(data)\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for preparing text data into sequences for training \n",
    "def data_sequencing(data):   \n",
    "    # integer encode sequences of words\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts([data])\n",
    "    with open('tokenizer.pkl', 'wb') as f: # Save the tokeniser by pickling it\n",
    "        pickle.dump(tokenizer, f)\n",
    "\n",
    "    encoded = tokenizer.texts_to_sequences([data])[0]\n",
    "    # retrieve vocabulary size\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    print('Vocabulary Size: %d' % vocab_size)\n",
    "    \n",
    "    # create line-based sequences\n",
    "    sequences = list()\n",
    "    rev_sequences = list()\n",
    "    for line in data.split('.'):\n",
    "        encoded = tokenizer.texts_to_sequences([line])[0]\n",
    "        rev_encoded = encoded[::-1]\n",
    "        for i in range(1, len(encoded)):\n",
    "            sequence = encoded[:i+1]\n",
    "            rev_sequence = rev_encoded[:i+1]\n",
    "            sequences.append(sequence)\n",
    "            rev_sequences.append(rev_sequence)\n",
    "    print('Total Sequences: %d' % len(sequences))\n",
    "    \n",
    "    \n",
    "    #find max sequence length \n",
    "    max_length = max([len(seq) for seq in sequences])\n",
    "    with open('max_length.pkl', 'wb') as f: # Save max_length by pickling it\n",
    "        pickle.dump(max_length, f)\n",
    "    print('Max Sequence Length: %d' % max_length)\n",
    "\n",
    "    # pad sequences and create the forward sequence\n",
    "    sequences = pad_sequences(sequences, maxlen=max_length, padding='pre')\n",
    "    # split into input and output elements\n",
    "    sequences = array(sequences)\n",
    "    X, y = sequences[:,:-1],sequences[:,-1]\n",
    "    \n",
    "    #pad sequences and create the reverse sequencing\n",
    "    rev_sequences = pad_sequences(rev_sequences, maxlen=max_length, padding='pre')\n",
    "    # split into input and output elements\n",
    "    rev_sequences = array(rev_sequences)\n",
    "    rev_X, rev_y = rev_sequences[:,:-1],rev_sequences[:,-1]\n",
    "\n",
    "    return X,y,rev_X,rev_y,max_length,vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 740\n",
      "Total Sequences: 1599\n",
      "Max Sequence Length: 56\n"
     ]
    }
   ],
   "source": [
    "#returning forward and reverse sequences along with max sequence \n",
    "#length from the data \n",
    "\n",
    "X,y,rev_X,rev_y,max_length,vocab_size = data_sequencing(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_12 (Embedding)    (None, 55, 100)           74000     \n",
      "                                                                 \n",
      " bidirectional_12 (Bidirecti  (None, 200)              160800    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 740)               148740    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 383,540\n",
      "Trainable params: 383,540\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define forward sequence model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size,100, input_length=max_length-1))\n",
    "#model.add(LSTM(100))\n",
    "model.add(Bidirectional(LSTM(100)))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_13 (Embedding)    (None, 55, 100)           74000     \n",
      "                                                                 \n",
      " bidirectional_13 (Bidirecti  (None, 200)              160800    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 740)               148740    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 383,540\n",
      "Trainable params: 383,540\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define reverse model\n",
    "rev_model = Sequential()\n",
    "rev_model.add(Embedding(vocab_size, 100, input_length=max_length-1))\n",
    "#rev_model.add(LSTM(100))\n",
    "rev_model.add(Bidirectional(LSTM(100)))\n",
    "rev_model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(rev_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 15s - loss: 6.5485 - accuracy: 0.0225 - 15s/epoch - 967ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 13s - loss: 6.0941 - accuracy: 0.0275 - 13s/epoch - 782ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 13s - loss: 5.9467 - accuracy: 0.0356 - 13s/epoch - 814ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 25s - loss: 5.9154 - accuracy: 0.0356 - 25s/epoch - 2s/step\n",
      "Epoch 5/100\n",
      "16/16 - 26s - loss: 5.9097 - accuracy: 0.0281 - 26s/epoch - 2s/step\n",
      "Epoch 6/100\n",
      "16/16 - 28s - loss: 5.8967 - accuracy: 0.0356 - 28s/epoch - 2s/step\n",
      "Epoch 7/100\n",
      "16/16 - 31s - loss: 5.8852 - accuracy: 0.0356 - 31s/epoch - 2s/step\n",
      "Epoch 8/100\n",
      "16/16 - 30s - loss: 5.8683 - accuracy: 0.0394 - 30s/epoch - 2s/step\n",
      "Epoch 9/100\n",
      "16/16 - 30s - loss: 5.8389 - accuracy: 0.0356 - 30s/epoch - 2s/step\n",
      "Epoch 10/100\n",
      "16/16 - 30s - loss: 5.7867 - accuracy: 0.0482 - 30s/epoch - 2s/step\n",
      "Epoch 11/100\n",
      "16/16 - 30s - loss: 5.7152 - accuracy: 0.0500 - 30s/epoch - 2s/step\n",
      "Epoch 12/100\n",
      "16/16 - 30s - loss: 5.6128 - accuracy: 0.0557 - 30s/epoch - 2s/step\n",
      "Epoch 13/100\n",
      "16/16 - 30s - loss: 5.4934 - accuracy: 0.0682 - 30s/epoch - 2s/step\n",
      "Epoch 14/100\n",
      "16/16 - 30s - loss: 5.3746 - accuracy: 0.0763 - 30s/epoch - 2s/step\n",
      "Epoch 15/100\n",
      "16/16 - 30s - loss: 5.2399 - accuracy: 0.0788 - 30s/epoch - 2s/step\n",
      "Epoch 16/100\n",
      "16/16 - 30s - loss: 5.1088 - accuracy: 0.1069 - 30s/epoch - 2s/step\n",
      "Epoch 17/100\n",
      "16/16 - 29s - loss: 4.9738 - accuracy: 0.1132 - 29s/epoch - 2s/step\n",
      "Epoch 18/100\n",
      "16/16 - 30s - loss: 4.8435 - accuracy: 0.1182 - 30s/epoch - 2s/step\n",
      "Epoch 19/100\n",
      "16/16 - 29s - loss: 4.7113 - accuracy: 0.1326 - 29s/epoch - 2s/step\n",
      "Epoch 20/100\n",
      "16/16 - 30s - loss: 4.5846 - accuracy: 0.1401 - 30s/epoch - 2s/step\n",
      "Epoch 21/100\n",
      "16/16 - 30s - loss: 4.4541 - accuracy: 0.1639 - 30s/epoch - 2s/step\n",
      "Epoch 22/100\n",
      "16/16 - 29s - loss: 4.3238 - accuracy: 0.1682 - 29s/epoch - 2s/step\n",
      "Epoch 23/100\n",
      "16/16 - 30s - loss: 4.1990 - accuracy: 0.1782 - 30s/epoch - 2s/step\n",
      "Epoch 24/100\n",
      "16/16 - 30s - loss: 4.0763 - accuracy: 0.1951 - 30s/epoch - 2s/step\n",
      "Epoch 25/100\n",
      "16/16 - 29s - loss: 3.9545 - accuracy: 0.2095 - 29s/epoch - 2s/step\n",
      "Epoch 26/100\n",
      "16/16 - 19s - loss: 3.8294 - accuracy: 0.2233 - 19s/epoch - 1s/step\n",
      "Epoch 27/100\n",
      "16/16 - 13s - loss: 3.7038 - accuracy: 0.2414 - 13s/epoch - 839ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 13s - loss: 3.5935 - accuracy: 0.2614 - 13s/epoch - 833ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 13s - loss: 3.4805 - accuracy: 0.2864 - 13s/epoch - 836ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 13s - loss: 3.3680 - accuracy: 0.3102 - 13s/epoch - 843ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 14s - loss: 3.2538 - accuracy: 0.3321 - 14s/epoch - 860ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 14s - loss: 3.1464 - accuracy: 0.3515 - 14s/epoch - 863ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 23s - loss: 3.0515 - accuracy: 0.3621 - 23s/epoch - 1s/step\n",
      "Epoch 34/100\n",
      "16/16 - 30s - loss: 2.9415 - accuracy: 0.4009 - 30s/epoch - 2s/step\n",
      "Epoch 35/100\n",
      "16/16 - 30s - loss: 2.8401 - accuracy: 0.4203 - 30s/epoch - 2s/step\n",
      "Epoch 36/100\n",
      "16/16 - 30s - loss: 2.7412 - accuracy: 0.4515 - 30s/epoch - 2s/step\n",
      "Epoch 37/100\n",
      "16/16 - 30s - loss: 2.6464 - accuracy: 0.4709 - 30s/epoch - 2s/step\n",
      "Epoch 38/100\n",
      "16/16 - 30s - loss: 2.5511 - accuracy: 0.4991 - 30s/epoch - 2s/step\n",
      "Epoch 39/100\n",
      "16/16 - 30s - loss: 2.4612 - accuracy: 0.5216 - 30s/epoch - 2s/step\n",
      "Epoch 40/100\n",
      "16/16 - 30s - loss: 2.3765 - accuracy: 0.5453 - 30s/epoch - 2s/step\n",
      "Epoch 41/100\n",
      "16/16 - 29s - loss: 2.2892 - accuracy: 0.5729 - 29s/epoch - 2s/step\n",
      "Epoch 42/100\n",
      "16/16 - 28s - loss: 2.1966 - accuracy: 0.6041 - 28s/epoch - 2s/step\n",
      "Epoch 43/100\n",
      "16/16 - 29s - loss: 2.1288 - accuracy: 0.6341 - 29s/epoch - 2s/step\n",
      "Epoch 44/100\n",
      "16/16 - 28s - loss: 2.0427 - accuracy: 0.6423 - 28s/epoch - 2s/step\n",
      "Epoch 45/100\n",
      "16/16 - 28s - loss: 1.9627 - accuracy: 0.6760 - 28s/epoch - 2s/step\n",
      "Epoch 46/100\n",
      "16/16 - 30s - loss: 1.8900 - accuracy: 0.6961 - 30s/epoch - 2s/step\n",
      "Epoch 47/100\n",
      "16/16 - 30s - loss: 1.8191 - accuracy: 0.7192 - 30s/epoch - 2s/step\n",
      "Epoch 48/100\n",
      "16/16 - 29s - loss: 1.7437 - accuracy: 0.7455 - 29s/epoch - 2s/step\n",
      "Epoch 49/100\n",
      "16/16 - 30s - loss: 1.6769 - accuracy: 0.7561 - 30s/epoch - 2s/step\n",
      "Epoch 50/100\n",
      "16/16 - 29s - loss: 1.6118 - accuracy: 0.7761 - 29s/epoch - 2s/step\n",
      "Epoch 51/100\n",
      "16/16 - 27s - loss: 1.5513 - accuracy: 0.7924 - 27s/epoch - 2s/step\n",
      "Epoch 52/100\n",
      "16/16 - 15s - loss: 1.4868 - accuracy: 0.8018 - 15s/epoch - 963ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 15s - loss: 1.4259 - accuracy: 0.8205 - 15s/epoch - 942ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 15s - loss: 1.3686 - accuracy: 0.8286 - 15s/epoch - 950ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 15s - loss: 1.3154 - accuracy: 0.8424 - 15s/epoch - 960ms/step\n",
      "Epoch 56/100\n",
      "16/16 - 15s - loss: 1.2608 - accuracy: 0.8474 - 15s/epoch - 958ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 16s - loss: 1.2085 - accuracy: 0.8630 - 16s/epoch - 974ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 16s - loss: 1.1576 - accuracy: 0.8718 - 16s/epoch - 973ms/step\n",
      "Epoch 59/100\n",
      "16/16 - 16s - loss: 1.1075 - accuracy: 0.8755 - 16s/epoch - 976ms/step\n",
      "Epoch 60/100\n",
      "16/16 - 23s - loss: 1.0572 - accuracy: 0.8856 - 23s/epoch - 1s/step\n",
      "Epoch 61/100\n",
      "16/16 - 19s - loss: 1.0161 - accuracy: 0.8906 - 19s/epoch - 1s/step\n",
      "Epoch 62/100\n",
      "16/16 - 17s - loss: 0.9778 - accuracy: 0.8993 - 17s/epoch - 1s/step\n",
      "Epoch 63/100\n",
      "16/16 - 17s - loss: 0.9396 - accuracy: 0.9068 - 17s/epoch - 1s/step\n",
      "Epoch 64/100\n",
      "16/16 - 17s - loss: 0.8986 - accuracy: 0.9131 - 17s/epoch - 1s/step\n",
      "Epoch 65/100\n",
      "16/16 - 17s - loss: 0.8614 - accuracy: 0.9181 - 17s/epoch - 1s/step\n",
      "Epoch 66/100\n",
      "16/16 - 18s - loss: 0.8225 - accuracy: 0.9250 - 18s/epoch - 1s/step\n",
      "Epoch 67/100\n",
      "16/16 - 17s - loss: 0.7859 - accuracy: 0.9281 - 17s/epoch - 1s/step\n",
      "Epoch 68/100\n",
      "16/16 - 17s - loss: 0.7579 - accuracy: 0.9325 - 17s/epoch - 1s/step\n",
      "Epoch 69/100\n",
      "16/16 - 17s - loss: 0.7302 - accuracy: 0.9393 - 17s/epoch - 1s/step\n",
      "Epoch 70/100\n",
      "16/16 - 25s - loss: 0.7020 - accuracy: 0.9375 - 25s/epoch - 2s/step\n",
      "Epoch 71/100\n",
      "16/16 - 29s - loss: 0.6691 - accuracy: 0.9450 - 29s/epoch - 2s/step\n",
      "Epoch 72/100\n",
      "16/16 - 30s - loss: 0.6462 - accuracy: 0.9481 - 30s/epoch - 2s/step\n",
      "Epoch 73/100\n",
      "16/16 - 30s - loss: 0.6187 - accuracy: 0.9531 - 30s/epoch - 2s/step\n",
      "Epoch 74/100\n",
      "16/16 - 30s - loss: 0.5938 - accuracy: 0.9525 - 30s/epoch - 2s/step\n",
      "Epoch 75/100\n",
      "16/16 - 30s - loss: 0.5717 - accuracy: 0.9537 - 30s/epoch - 2s/step\n",
      "Epoch 76/100\n",
      "16/16 - 30s - loss: 0.5472 - accuracy: 0.9587 - 30s/epoch - 2s/step\n",
      "Epoch 77/100\n",
      "16/16 - 30s - loss: 0.5260 - accuracy: 0.9568 - 30s/epoch - 2s/step\n",
      "Epoch 78/100\n",
      "16/16 - 29s - loss: 0.5038 - accuracy: 0.9619 - 29s/epoch - 2s/step\n",
      "Epoch 79/100\n",
      "16/16 - 30s - loss: 0.4859 - accuracy: 0.9631 - 30s/epoch - 2s/step\n",
      "Epoch 80/100\n",
      "16/16 - 30s - loss: 0.4686 - accuracy: 0.9644 - 30s/epoch - 2s/step\n",
      "Epoch 81/100\n",
      "16/16 - 30s - loss: 0.4577 - accuracy: 0.9606 - 30s/epoch - 2s/step\n",
      "Epoch 82/100\n",
      "16/16 - 30s - loss: 0.4461 - accuracy: 0.9662 - 30s/epoch - 2s/step\n",
      "Epoch 83/100\n",
      "16/16 - 31s - loss: 0.4253 - accuracy: 0.9662 - 31s/epoch - 2s/step\n",
      "Epoch 84/100\n",
      "16/16 - 32s - loss: 0.4104 - accuracy: 0.9681 - 32s/epoch - 2s/step\n",
      "Epoch 85/100\n",
      "16/16 - 32s - loss: 0.3955 - accuracy: 0.9669 - 32s/epoch - 2s/step\n",
      "Epoch 86/100\n",
      "16/16 - 32s - loss: 0.3789 - accuracy: 0.9675 - 32s/epoch - 2s/step\n",
      "Epoch 87/100\n",
      "16/16 - 32s - loss: 0.3760 - accuracy: 0.9662 - 32s/epoch - 2s/step\n",
      "Epoch 88/100\n",
      "16/16 - 31s - loss: 0.3803 - accuracy: 0.9644 - 31s/epoch - 2s/step\n",
      "Epoch 89/100\n",
      "16/16 - 31s - loss: 0.3630 - accuracy: 0.9675 - 31s/epoch - 2s/step\n",
      "Epoch 90/100\n",
      "16/16 - 32s - loss: 0.3525 - accuracy: 0.9650 - 32s/epoch - 2s/step\n",
      "Epoch 91/100\n",
      "16/16 - 31s - loss: 0.3345 - accuracy: 0.9731 - 31s/epoch - 2s/step\n",
      "Epoch 92/100\n",
      "16/16 - 31s - loss: 0.3129 - accuracy: 0.9762 - 31s/epoch - 2s/step\n",
      "Epoch 93/100\n",
      "16/16 - 27s - loss: 0.2983 - accuracy: 0.9781 - 27s/epoch - 2s/step\n",
      "Epoch 94/100\n",
      "16/16 - 14s - loss: 0.2846 - accuracy: 0.9781 - 14s/epoch - 882ms/step\n",
      "Epoch 95/100\n",
      "16/16 - 14s - loss: 0.2754 - accuracy: 0.9787 - 14s/epoch - 882ms/step\n",
      "Epoch 96/100\n",
      "16/16 - 14s - loss: 0.2655 - accuracy: 0.9762 - 14s/epoch - 895ms/step\n",
      "Epoch 97/100\n",
      "16/16 - 14s - loss: 0.2561 - accuracy: 0.9794 - 14s/epoch - 879ms/step\n",
      "Epoch 98/100\n",
      "16/16 - 14s - loss: 0.2471 - accuracy: 0.9794 - 14s/epoch - 886ms/step\n",
      "Epoch 99/100\n",
      "16/16 - 14s - loss: 0.2408 - accuracy: 0.9800 - 14s/epoch - 867ms/step\n",
      "Epoch 100/100\n",
      "16/16 - 14s - loss: 0.2314 - accuracy: 0.9806 - 14s/epoch - 903ms/step\n"
     ]
    }
   ],
   "source": [
    "# compile forward sequence network\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit network\n",
    "model.fit(X, y,batch_size=100, epochs=100, verbose=2)\n",
    "# save the model to file\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 - 11s - loss: 6.5387 - accuracy: 0.0275 - 11s/epoch - 680ms/step\n",
      "Epoch 2/100\n",
      "16/16 - 8s - loss: 6.0607 - accuracy: 0.0344 - 8s/epoch - 488ms/step\n",
      "Epoch 3/100\n",
      "16/16 - 8s - loss: 5.9114 - accuracy: 0.0344 - 8s/epoch - 493ms/step\n",
      "Epoch 4/100\n",
      "16/16 - 8s - loss: 5.8846 - accuracy: 0.0381 - 8s/epoch - 493ms/step\n",
      "Epoch 5/100\n",
      "16/16 - 8s - loss: 5.8680 - accuracy: 0.0375 - 8s/epoch - 490ms/step\n",
      "Epoch 6/100\n",
      "16/16 - 8s - loss: 5.8488 - accuracy: 0.0400 - 8s/epoch - 489ms/step\n",
      "Epoch 7/100\n",
      "16/16 - 8s - loss: 5.8125 - accuracy: 0.0388 - 8s/epoch - 495ms/step\n",
      "Epoch 8/100\n",
      "16/16 - 8s - loss: 5.7752 - accuracy: 0.0500 - 8s/epoch - 492ms/step\n",
      "Epoch 9/100\n",
      "16/16 - 8s - loss: 5.7206 - accuracy: 0.0438 - 8s/epoch - 492ms/step\n",
      "Epoch 10/100\n",
      "16/16 - 8s - loss: 5.6321 - accuracy: 0.0475 - 8s/epoch - 492ms/step\n",
      "Epoch 11/100\n",
      "16/16 - 8s - loss: 5.5474 - accuracy: 0.0519 - 8s/epoch - 495ms/step\n",
      "Epoch 12/100\n",
      "16/16 - 8s - loss: 5.4513 - accuracy: 0.0550 - 8s/epoch - 496ms/step\n",
      "Epoch 13/100\n",
      "16/16 - 8s - loss: 5.3432 - accuracy: 0.0613 - 8s/epoch - 494ms/step\n",
      "Epoch 14/100\n",
      "16/16 - 8s - loss: 5.2720 - accuracy: 0.0625 - 8s/epoch - 497ms/step\n",
      "Epoch 15/100\n",
      "16/16 - 8s - loss: 5.1555 - accuracy: 0.0819 - 8s/epoch - 494ms/step\n",
      "Epoch 16/100\n",
      "16/16 - 8s - loss: 5.0308 - accuracy: 0.0819 - 8s/epoch - 504ms/step\n",
      "Epoch 17/100\n",
      "16/16 - 8s - loss: 4.9267 - accuracy: 0.0988 - 8s/epoch - 500ms/step\n",
      "Epoch 18/100\n",
      "16/16 - 8s - loss: 4.7958 - accuracy: 0.1113 - 8s/epoch - 500ms/step\n",
      "Epoch 19/100\n",
      "16/16 - 8s - loss: 4.6867 - accuracy: 0.1276 - 8s/epoch - 522ms/step\n",
      "Epoch 20/100\n",
      "16/16 - 8s - loss: 4.5781 - accuracy: 0.1388 - 8s/epoch - 527ms/step\n",
      "Epoch 21/100\n",
      "16/16 - 8s - loss: 4.4530 - accuracy: 0.1432 - 8s/epoch - 505ms/step\n",
      "Epoch 22/100\n",
      "16/16 - 8s - loss: 4.3416 - accuracy: 0.1551 - 8s/epoch - 505ms/step\n",
      "Epoch 23/100\n",
      "16/16 - 8s - loss: 4.2411 - accuracy: 0.1676 - 8s/epoch - 508ms/step\n",
      "Epoch 24/100\n",
      "16/16 - 8s - loss: 4.1335 - accuracy: 0.1801 - 8s/epoch - 500ms/step\n",
      "Epoch 25/100\n",
      "16/16 - 8s - loss: 4.0331 - accuracy: 0.1895 - 8s/epoch - 501ms/step\n",
      "Epoch 26/100\n",
      "16/16 - 8s - loss: 3.9303 - accuracy: 0.2033 - 8s/epoch - 499ms/step\n",
      "Epoch 27/100\n",
      "16/16 - 8s - loss: 3.8331 - accuracy: 0.2176 - 8s/epoch - 502ms/step\n",
      "Epoch 28/100\n",
      "16/16 - 8s - loss: 3.7405 - accuracy: 0.2364 - 8s/epoch - 502ms/step\n",
      "Epoch 29/100\n",
      "16/16 - 8s - loss: 3.7213 - accuracy: 0.2408 - 8s/epoch - 506ms/step\n",
      "Epoch 30/100\n",
      "16/16 - 8s - loss: 3.6453 - accuracy: 0.2452 - 8s/epoch - 515ms/step\n",
      "Epoch 31/100\n",
      "16/16 - 9s - loss: 3.5429 - accuracy: 0.2664 - 9s/epoch - 566ms/step\n",
      "Epoch 32/100\n",
      "16/16 - 8s - loss: 3.4394 - accuracy: 0.2777 - 8s/epoch - 523ms/step\n",
      "Epoch 33/100\n",
      "16/16 - 8s - loss: 3.3440 - accuracy: 0.2877 - 8s/epoch - 521ms/step\n",
      "Epoch 34/100\n",
      "16/16 - 8s - loss: 3.2450 - accuracy: 0.3158 - 8s/epoch - 526ms/step\n",
      "Epoch 35/100\n",
      "16/16 - 8s - loss: 3.1490 - accuracy: 0.3358 - 8s/epoch - 529ms/step\n",
      "Epoch 36/100\n",
      "16/16 - 8s - loss: 3.0373 - accuracy: 0.3502 - 8s/epoch - 530ms/step\n",
      "Epoch 37/100\n",
      "16/16 - 8s - loss: 2.9499 - accuracy: 0.3652 - 8s/epoch - 528ms/step\n",
      "Epoch 38/100\n",
      "16/16 - 9s - loss: 2.8604 - accuracy: 0.3921 - 9s/epoch - 533ms/step\n",
      "Epoch 39/100\n",
      "16/16 - 9s - loss: 2.7983 - accuracy: 0.4103 - 9s/epoch - 532ms/step\n",
      "Epoch 40/100\n",
      "16/16 - 9s - loss: 2.7170 - accuracy: 0.4296 - 9s/epoch - 537ms/step\n",
      "Epoch 41/100\n",
      "16/16 - 9s - loss: 2.6341 - accuracy: 0.4628 - 9s/epoch - 534ms/step\n",
      "Epoch 42/100\n",
      "16/16 - 9s - loss: 2.5441 - accuracy: 0.4903 - 9s/epoch - 534ms/step\n",
      "Epoch 43/100\n",
      "16/16 - 9s - loss: 2.4764 - accuracy: 0.5128 - 9s/epoch - 542ms/step\n",
      "Epoch 44/100\n",
      "16/16 - 9s - loss: 2.3951 - accuracy: 0.5341 - 9s/epoch - 543ms/step\n",
      "Epoch 45/100\n",
      "16/16 - 9s - loss: 2.3223 - accuracy: 0.5647 - 9s/epoch - 544ms/step\n",
      "Epoch 46/100\n",
      "16/16 - 9s - loss: 2.2558 - accuracy: 0.5835 - 9s/epoch - 544ms/step\n",
      "Epoch 47/100\n",
      "16/16 - 9s - loss: 2.1817 - accuracy: 0.6123 - 9s/epoch - 545ms/step\n",
      "Epoch 48/100\n",
      "16/16 - 9s - loss: 2.1129 - accuracy: 0.6254 - 9s/epoch - 548ms/step\n",
      "Epoch 49/100\n",
      "16/16 - 9s - loss: 2.0512 - accuracy: 0.6517 - 9s/epoch - 550ms/step\n",
      "Epoch 50/100\n",
      "16/16 - 9s - loss: 2.0130 - accuracy: 0.6529 - 9s/epoch - 554ms/step\n",
      "Epoch 51/100\n",
      "16/16 - 9s - loss: 1.9413 - accuracy: 0.6685 - 9s/epoch - 555ms/step\n",
      "Epoch 52/100\n",
      "16/16 - 9s - loss: 1.8600 - accuracy: 0.6942 - 9s/epoch - 572ms/step\n",
      "Epoch 53/100\n",
      "16/16 - 9s - loss: 1.7903 - accuracy: 0.7248 - 9s/epoch - 559ms/step\n",
      "Epoch 54/100\n",
      "16/16 - 9s - loss: 1.7224 - accuracy: 0.7398 - 9s/epoch - 563ms/step\n",
      "Epoch 55/100\n",
      "16/16 - 9s - loss: 1.6681 - accuracy: 0.7473 - 9s/epoch - 571ms/step\n",
      "Epoch 56/100\n",
      "16/16 - 9s - loss: 1.6039 - accuracy: 0.7742 - 9s/epoch - 567ms/step\n",
      "Epoch 57/100\n",
      "16/16 - 9s - loss: 1.5551 - accuracy: 0.7805 - 9s/epoch - 568ms/step\n",
      "Epoch 58/100\n",
      "16/16 - 9s - loss: 1.5008 - accuracy: 0.7992 - 9s/epoch - 569ms/step\n",
      "Epoch 59/100\n",
      "16/16 - 9s - loss: 1.4508 - accuracy: 0.8043 - 9s/epoch - 568ms/step\n",
      "Epoch 60/100\n",
      "16/16 - 9s - loss: 1.3949 - accuracy: 0.8211 - 9s/epoch - 572ms/step\n",
      "Epoch 61/100\n",
      "16/16 - 9s - loss: 1.3480 - accuracy: 0.8343 - 9s/epoch - 570ms/step\n",
      "Epoch 62/100\n",
      "16/16 - 9s - loss: 1.3087 - accuracy: 0.8468 - 9s/epoch - 571ms/step\n",
      "Epoch 63/100\n",
      "16/16 - 9s - loss: 1.2681 - accuracy: 0.8474 - 9s/epoch - 571ms/step\n",
      "Epoch 64/100\n",
      "16/16 - 9s - loss: 1.2280 - accuracy: 0.8487 - 9s/epoch - 581ms/step\n",
      "Epoch 65/100\n",
      "16/16 - 9s - loss: 1.1830 - accuracy: 0.8674 - 9s/epoch - 592ms/step\n",
      "Epoch 66/100\n",
      "16/16 - 9s - loss: 1.1378 - accuracy: 0.8762 - 9s/epoch - 576ms/step\n",
      "Epoch 67/100\n",
      "16/16 - 9s - loss: 1.0991 - accuracy: 0.8849 - 9s/epoch - 572ms/step\n",
      "Epoch 68/100\n",
      "16/16 - 9s - loss: 1.0612 - accuracy: 0.8974 - 9s/epoch - 570ms/step\n",
      "Epoch 69/100\n",
      "16/16 - 9s - loss: 1.0225 - accuracy: 0.8949 - 9s/epoch - 572ms/step\n",
      "Epoch 70/100\n",
      "16/16 - 9s - loss: 0.9882 - accuracy: 0.9031 - 9s/epoch - 575ms/step\n",
      "Epoch 71/100\n",
      "16/16 - 9s - loss: 0.9528 - accuracy: 0.9143 - 9s/epoch - 579ms/step\n",
      "Epoch 72/100\n",
      "16/16 - 9s - loss: 0.9222 - accuracy: 0.9168 - 9s/epoch - 581ms/step\n",
      "Epoch 73/100\n",
      "16/16 - 9s - loss: 0.8912 - accuracy: 0.9256 - 9s/epoch - 574ms/step\n",
      "Epoch 74/100\n",
      "16/16 - 9s - loss: 0.8631 - accuracy: 0.9325 - 9s/epoch - 577ms/step\n",
      "Epoch 75/100\n",
      "16/16 - 9s - loss: 0.8351 - accuracy: 0.9343 - 9s/epoch - 578ms/step\n",
      "Epoch 76/100\n",
      "16/16 - 9s - loss: 0.8069 - accuracy: 0.9362 - 9s/epoch - 582ms/step\n",
      "Epoch 77/100\n",
      "16/16 - 9s - loss: 0.7781 - accuracy: 0.9431 - 9s/epoch - 587ms/step\n",
      "Epoch 78/100\n",
      "16/16 - 9s - loss: 0.7589 - accuracy: 0.9412 - 9s/epoch - 585ms/step\n",
      "Epoch 79/100\n",
      "16/16 - 9s - loss: 0.7290 - accuracy: 0.9450 - 9s/epoch - 581ms/step\n",
      "Epoch 80/100\n",
      "16/16 - 9s - loss: 0.7079 - accuracy: 0.9481 - 9s/epoch - 591ms/step\n",
      "Epoch 81/100\n",
      "16/16 - 9s - loss: 0.8293 - accuracy: 0.9043 - 9s/epoch - 591ms/step\n",
      "Epoch 82/100\n",
      "16/16 - 9s - loss: 0.7853 - accuracy: 0.9093 - 9s/epoch - 582ms/step\n",
      "Epoch 83/100\n",
      "16/16 - 10s - loss: 0.7110 - accuracy: 0.9381 - 10s/epoch - 645ms/step\n",
      "Epoch 84/100\n",
      "16/16 - 10s - loss: 0.6601 - accuracy: 0.9531 - 10s/epoch - 598ms/step\n",
      "Epoch 85/100\n",
      "16/16 - 9s - loss: 0.6285 - accuracy: 0.9543 - 9s/epoch - 594ms/step\n",
      "Epoch 86/100\n",
      "16/16 - 9s - loss: 0.5977 - accuracy: 0.9587 - 9s/epoch - 585ms/step\n",
      "Epoch 87/100\n",
      "16/16 - 10s - loss: 0.5722 - accuracy: 0.9606 - 10s/epoch - 627ms/step\n",
      "Epoch 88/100\n",
      "16/16 - 9s - loss: 0.5503 - accuracy: 0.9625 - 9s/epoch - 587ms/step\n",
      "Epoch 89/100\n",
      "16/16 - 9s - loss: 0.5573 - accuracy: 0.9581 - 9s/epoch - 588ms/step\n",
      "Epoch 90/100\n",
      "16/16 - 9s - loss: 0.5729 - accuracy: 0.9500 - 9s/epoch - 579ms/step\n",
      "Epoch 91/100\n",
      "16/16 - 9s - loss: 0.5470 - accuracy: 0.9525 - 9s/epoch - 583ms/step\n",
      "Epoch 92/100\n",
      "16/16 - 9s - loss: 0.5272 - accuracy: 0.9568 - 9s/epoch - 582ms/step\n",
      "Epoch 93/100\n",
      "16/16 - 9s - loss: 0.5010 - accuracy: 0.9650 - 9s/epoch - 573ms/step\n",
      "Epoch 94/100\n",
      "16/16 - 9s - loss: 0.4781 - accuracy: 0.9669 - 9s/epoch - 568ms/step\n",
      "Epoch 95/100\n",
      "16/16 - 9s - loss: 0.4575 - accuracy: 0.9694 - 9s/epoch - 578ms/step\n",
      "Epoch 96/100\n",
      "16/16 - 9s - loss: 0.4396 - accuracy: 0.9675 - 9s/epoch - 581ms/step\n",
      "Epoch 97/100\n",
      "16/16 - 9s - loss: 0.4248 - accuracy: 0.9694 - 9s/epoch - 587ms/step\n",
      "Epoch 98/100\n",
      "16/16 - 9s - loss: 0.4119 - accuracy: 0.9712 - 9s/epoch - 568ms/step\n",
      "Epoch 99/100\n",
      "16/16 - 9s - loss: 0.3956 - accuracy: 0.9700 - 9s/epoch - 564ms/step\n",
      "Epoch 100/100\n",
      "16/16 - 9s - loss: 0.3839 - accuracy: 0.9712 - 9s/epoch - 563ms/step\n"
     ]
    }
   ],
   "source": [
    "# compile reverse sequence network\n",
    "rev_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit network\n",
    "rev_model.fit(rev_X, rev_y,batch_size=100, epochs=100, verbose=2)\n",
    "# save the model to file\n",
    "rev_model.save('rev_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sequence using a language model\n",
    "def generate_seq(model, tokenizer, max_length, seed_text):\n",
    "    if seed_text == \"\":\n",
    "        return \"\"\n",
    "    else:\n",
    "        in_text = seed_text\n",
    "        n_words = 1\n",
    "        n_preds = 5 #number of words to predict for the seed text\n",
    "        pred_words = \"\"\n",
    "        # generate a fixed number of words\n",
    "        for _ in range(n_words):\n",
    "            # encode the text as integer\n",
    "            encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "            # pre-pad sequences to a fixed length\n",
    "            encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
    "            # predict probabilities for each word\n",
    "            proba = model.predict(encoded, verbose=0).flatten()\n",
    "            #take the n_preds highest probability classes \n",
    "            yhat = numpy.argsort(-proba)[:n_preds] \n",
    "            # map predicted words index to word\n",
    "            out_word = ''\n",
    "\n",
    "            for _ in range(n_preds):\n",
    "                for word, index in tokenizer.word_index.items():\n",
    "                    if index == yhat[_] and word not in stopwords: # CHECK THIS \n",
    "                        out_word = word\n",
    "                        pred_words += ' ' + out_word\n",
    "                        #print(out_word)\n",
    "                        break\n",
    "\n",
    "\n",
    "        return pred_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = load_model('model.h5')\n",
    "rev_model = load_model('rev_model.h5')\n",
    "\n",
    "#load tokeniser and max_length\n",
    "with open('tokenizer.pkl', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "    \n",
    "with open('max_length.pkl', 'rb') as f:\n",
    "    max_length = pickle.load(f)\n",
    "    \n",
    "\n",
    "#load spacy GloVe Model\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "#loading stopwords to improve relevant word predictions    \n",
    "stopwords= nlp.Defaults.stop_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find and set embeddings for OOV words\n",
    "def set_embedding_for_oov(doc):\n",
    "    #checking for oov words and adding embedding\n",
    "    print(type(doc))\n",
    "    j=0 #for keeping track of index to replace\n",
    "    changed_string=\"\"\n",
    "    doc2=doc\n",
    "    for token in doc:\n",
    "        changed_string=changed_string+str(token.text_with_ws)\n",
    "        if token.is_oov == True:\n",
    "\n",
    "            \n",
    "            \n",
    "            before_text = doc[:token.i].text\n",
    "            after_text = str(array(doc)[:token.i:-1]).replace('[','').replace(']','')\n",
    "\n",
    "            pred_before = generate_seq(model, tokenizer, max_length-1, before_text).split()\n",
    "            pred_after = generate_seq(rev_model, tokenizer, max_length-1, after_text).split()\n",
    "            \n",
    "            embedding = numpy.zeros((300,))\n",
    "\n",
    "            i=len(before_text)\n",
    "            print('Words predicted from forward sequence model:')\n",
    "            for word in pred_before:\n",
    "                print(word)\n",
    "                embedding += i*nlp.vocab.get_vector(word)\n",
    "                i= i*.5\n",
    "            i=len(after_text)\n",
    "            print('Words predicted from reverse sequence model:')\n",
    "            for word in pred_after:\n",
    "                print(word)\n",
    "                embedding += i*nlp.vocab.get_vector(word)\n",
    "                i= i*.5\n",
    "            nlp.vocab.set_vector(token.text, embedding)  #CHECK: So we don't include the shitty words?\n",
    "\n",
    "            \n",
    "        \n",
    "           \n",
    "             \n",
    "            #set vector back to zero?\n",
    "            #nlp.vocab.set_vector(token.text, 0)\n",
    "\n",
    "##########################################################################################################\n",
    "            \n",
    "            #Locate similar words\n",
    "            by_similarity = sorted(token.vocab, key=lambda w: token.similarity(w), reverse=True)\n",
    "            #find the closest word to the token to be a replacement\n",
    "            replace=[w.orth_ for w in by_similarity[:3]][2]\n",
    "            #cast to string\n",
    "            token=str(token)\n",
    "         \n",
    "            \n",
    "            \n",
    "            changed_string=changed_string.replace(token, replace)\n",
    "\n",
    "            #create new doc with replaced word\n",
    "            doc2=nlp.make_doc(changed_string)\n",
    "            \n",
    "            j=j+1\n",
    "\n",
    "        doc2=nlp.make_doc(changed_string)\n",
    "\n",
    "    #assign original document to new document and return original document\n",
    "    doc=doc2    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.doc.Doc'>\n",
      "Words predicted from forward sequence model:\n",
      "stolen\n",
      "concentrated\n",
      "ready\n",
      "Words predicted from reverse sequence model:\n",
      "team\n",
      "plans\n",
      "topic\n",
      "members\n",
      "trucked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsedl\\AppData\\Local\\Temp\\ipykernel_21384\\1950521624.py:46: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  by_similarity = sorted(token.vocab, key=lambda w: token.similarity(w), reverse=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words predicted from forward sequence model:\n",
      "stolen\n",
      "concentrated\n",
      "ready\n",
      "Words predicted from reverse sequence model:\n",
      "team\n",
      "plans\n",
      "topic\n",
      "members\n",
      "trucked\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "I fdahfladfla that student thinki benefit comfortab learning at home,because they wont have to change and get up early in the morning to shower and do there hair. taking only classes helps them because at there house they'll be pay more attention. they will be comfortab at home. The hardest part of school is getting ready. you wake up go brush your teeth and go to your closet and look at your cloths. after you think you picked a outfit u go look in the mirror and youll either not like it or you look and see a stain. Then you'll have to change. with the online classes you can wear anything and stay home and you wont need to stress about what to wear. most students usually take showers before school. they either take it before they sleep or when they wake up. some students do both to smell good. that causes them do miss the bus and effects on there lesson time cause they come late to school. when u have online classes u wont need to miss lessons cause you can get everything set up and go take a shower and when u get out your ready to go. when your home your comfortable and you pay attention. it gives then an advantage to be smarter and even pass there classmates on class work. public schools are difficult even if you try. some teacher dont know how to teach it in then way that students understand it. that causes students to fail and they may repeat the class. "
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"I fdahfladfla that student wollld benefit follll learning at home,because they wont have to change and get up early in the morning to shower and do there hair. taking only classes helps them because at there house they'll be pay more attention. they will be comfortab at home. The hardest part of school is getting ready. you wake up go brush your teeth and go to your closet and look at your cloths. after you think you picked a outfit u go look in the mirror and youll either not like it or you look and see a stain. Then you'll have to change. with the online classes you can wear anything and stay home and you wont need to stress about what to wear. most students usually take showers before school. they either take it before they sleep or when they wake up. some students do both to smell good. that causes them do miss the bus and effects on there lesson time cause they come late to school. when u have online classes u wont need to miss lessons cause you can get everything set up and go take a shower and when u get out your ready to go. when your home your comfortable and you pay attention. it gives then an advantage to be smarter and even pass there classmates on class work. public schools are difficult even if you try. some teacher dont know how to teach it in then way that students understand it. that causes students to fail and they may repeat the class. \"\n",
    ")\n",
    "#print(nlp.vocab.get_vector('studen'))\n",
    "doc=set_embedding_for_oov(doc)\n",
    "#print(nlp.vocab.get_vector('studen'))\n",
    "doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsedl\\AppData\\Local\\Temp\\ipykernel_21384\\1143453434.py:3: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  by_similarity = sorted(word.vocab, key=lambda w: word.similarity(w), reverse=True)\n"
     ]
    }
   ],
   "source": [
    "lis=most_similar(nlp('comfortab'))[0]\n",
    "print(type(lis))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find most similar words\n",
    "def most_similar(word):\n",
    "    by_similarity = sorted(word.vocab, key=lambda w: word.similarity(w), reverse=True)\n",
    "    return [w.orth_ for w in by_similarity[:1]] #change :x for x amoint of similar words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
